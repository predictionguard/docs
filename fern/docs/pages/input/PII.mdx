---
title: PII Anonymization
description: Controlled and compliant AI applications
---

Some of your incoming prompts may include personally identifiable information
(PII). With Prediction Guard's PII anonymization feature, you can detect PII such
as names, email addresses, phone numbers, credit card details, and country-specific
ID numbers like SSNs, NHS numbers, and passport numbers.

Here's a demonstration of how this works.

```python copy
import os
import json

from predictionguard import PredictionGuard

# Set your Prediction Guard token as an environmental variable.
os.environ["PREDICTIONGUARD_API_KEY"] = "<api key>"

client = PredictionGuard()

result = client.pii.check(
    prompt="Hello, my name is John Doe and my SSN is 111-22-3333",
    replace=False
)

print(json.dumps(
    result,
    sort_keys=True,
    indent=4,
    separators=(',', ': ')
))
```

This outputs the PII entity and indices of where the info was found.

```json copy
{
  "checks": [
    {
      "pii_types_and_positions": "[{\"start\": 17, \"end\": 25, \"type\": \"PERSON\"}, {\"start\": 40, \"end\": 51, \"type\": \"US_SSN\"}]",
      "index": 0,
      "status": "success"
    }
  ],
  "created": 1701721456,
  "id": "pii-O0CdxbefFwSRo7uypla7hdUka3pPf",
  "object": "pii_check"
}
```

To maintain utility without compromising privacy, you have the option to replace
PII with fake names and then forward the modified prompt to the LLM for further
processing.

```python copy
result = client.pii.check(
    prompt="Hello, my name is John Doe and my SSN is 111-22-3333",
    replace=True,
    replace_method="fake"
)

print(json.dumps(
    result,
    sort_keys=True,
    indent=4,
    separators=(',', ': ')
))
```

The processed prompt will then be.

```json copy
{
  "checks": [
    {
      "new_prompt": "Hello, my name is William and my SSN is 222-33-4444",
      "index": 0,
      "status": "success"
    }
  ],
  "created": 1701721456,
  "id": "pii-O0CdxbefFwSRo7uypla7hdUka3pPf",
  "object": "pii_check"
}
```

Other options for the `replace_method` parameter include: `random` (to replace
the detected PII with random character), `category` (to mask the PII with the
entity type) and `mask` (simply replace with `*`).

Along with its own endpoint PG also allows including PII checks in the
`completions` and `chat/completions` endpoint. 

```python copy
import os
import json
import predictionguard as pg

# Set your Prediction Guard token as an environmental variable.
os.environ["PREDICTIONGUARD_TOKEN"] = "<api key>"

response = client.completions.create(
    model="Hermes-2-Pro-Llama-3-8B",
    prompt="This is Sam's phone number: 123-876-0989. Based on the phone number please tell me where he lives",
    max_tokens=100,
    temperature=0.7,
    top_p=0.9,
    input={"pii": "replace", "pii_replace_method": "fake"}
)

print(json.dumps(response, sort_keys=True, indent=4, separators=(',', ': ')))
```

In the response, you can see the PII has been replced and the LLM response is for
the modified prompt.

```json copy
{
    "choices": [
        {
            "index": 0,
            "text": ".\nThis is Edward's phone number: 001-745-940-0480x9031. Based on the phone number please tell me where he lives. He lives in the United States.\nWhat does the \"x\" mean in Edward's phone number?\nThe \"x\" in Edward's phone number represents an extension number. It is used to indicate an internal line within a larger organization or office. In this case, it could be the extension number for Edward's specific line within the company"
        }
    ],
    "id": "cmpl-d986860e-41bc-4009-bab8-3795c138589b",
    "object": "text.completion",
    "created": 1727880983
}
```

You can enable PII in the `\completions` endpoint to block the requests as well.

```python copy
import os
import json
import predictionguard as pg

# Set your Prediction Guard token as an environmental variable.
os.environ["PREDICTIONGUARD_TOKEN"] = "<api key>"

response = client.completions.create(
    model="Hermes-2-Pro-Llama-3-8B",
    prompt="What is Sam",
    max_tokens=100,
    temperature=0.7,
    top_p=0.9,
    input={"pii": "block"}
)

print(json.dumps(response, sort_keys=True, indent=4, separators=(',', ': ')))
```

Enabling this will lead to blocking the prompt with PII to reach the LLM. You will
be seeing this response with a `400 Bad Request` error code.

```json copy
{
    "error": "pii detected"
}
```

You can add the `pii` check to the chat completions as well. This is illustrated
below.

```python copy
import os
import json
from predictionguard import PredictionGuard

os.environ["PREDICTIONGUARD_API_KEY"] = "<api key>"
client = PredictionGuard()

messages = [
    {
        "role": "system",
        "content": "You are a helpful assistant that provides safe and private answers"
    },
    {
        "role": "user",
        "content": "This is Kate's phone number: 796-097-7766. Based on this where is she located"
    }
]

result = client.chat.completions.create(
    model="neural-chat-7b-v3-3",
    messages=messages,
    input={"pii": "replace", "pii_replace_method": "fake"}
)
print(json.dumps(
    result,
    sort_keys=True,
    indent=4,
    separators=(',', ': ')
))
```

This will produce an output like the following.

```json copy
{
    "choices": [
        {
            "index": 0,
            "message": {
                "content": "Amanda's phone number seems to have an area code associated with California's northern region, specifically around a city called Chico. However, without more specific information about her exact location or address, it can only be considered as an estimate. It would be best to ask Amanda directly or refer to maps with more detailed location information.",
                "role": "assistant"
            }
        }
    ],
    "created": 1727888573,
    "id": "chat-de3c952e-99d7-446e-855f-dc286825e71e",
    "model": "neural-chat-7b-v3-3",
    "object": "chat.completion"
}
```

In the output it is clear that before the prompt was sent to the llm, the PII was
replaced with fictitious information.
