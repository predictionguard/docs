---
title: Embeddings
---

You can get privacy-conserving text and image embeddings from 
[available models](/options/enumerations) using a call to the `/embeddings` REST
API endpoint or any of the official SDKs (Python, Go, Rust, JS, or cURL).

## Generate Embeddings

To generate embeddings, you can use the following code examples. Depending on your
preference or requirements, select the appropriate method for your application.
This functionality accepts text and image inputs, and supports batching multiple
inputs. The Go REST API only supports images that are input as a base64 encoded
string, whereas the python client supports image files, image urls, and images
encoded in a base64 string.

<CodeBlocks>
    <CodeBlock title="Python">
    ```python
    import os
    import json

    from predictionguard import PredictionGuard

    # Set your Prediction Guard token as an environmental variable.
    os.environ["PREDICTIONGUARD_API_KEY"] = "<api key>"

    client = PredictionGuard()

    response = client.embeddings.create(
      model="bridgetower-large-itm-mlm-itc",
      input=[
        {
            "text": "Tell me a joke.",
            "image": "https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg"
        }
      ]
    )

    print(json.dumps(
        response,
        sort_keys=True,
        indent=4,
        separators=(',', ': ')
    ))
    ```
    </CodeBlock>

    <CodeBlock title="Go">
    ```go
    package main

    import (
        "context"
        "fmt"
        "log"
        "os"
        "time"

        "github.com/predictionguard/go-client"
    )

    func main() {
        if err := run(); err != nil {
            log.Fatalln(err)
        }
    }

    func run() error {
        host := "https://api.predictionguard.com"
        apiKey := os.Getenv("PGKEY")

        logger := func(ctx context.Context, msg string, v ...any) {
            s := fmt.Sprintf("msg: %s", msg)
            for i := 0; i < len(v); i = i + 2 {
                s = s + fmt.Sprintf(", %s: %v", v[i], v[i+1])
            }
            log.Println(s)
        }

        cln := client.New(logger, host, apiKey)

        ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
        defer cancel()

        image, err := client.NewImageNetwork("https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg")
        if err != nil {
            return fmt.Errorf("ERROR: %w", err)
        }

        input := []client.EmbeddingInput{
            {
                Text:  "Tell me a joke.",
                Image: image,
            },
        }

        resp, err := cln.Embedding(ctx, input)
        if err != nil {
            return fmt.Errorf("ERROR: %w", err)
        }

        for _, data := range resp.Data {
            fmt.Print(data.Embedding)
        }

        return nil
    }
    ```
    </CodeBlock>

    <CodeBlock title="Rust">
    ```rust
    extern crate prediction_guard as pg_client;

    use pg_client::{client, embedding, models};

    #[tokio::main]
    async fn main() {
        let pg_env = client::PgEnvironment::from_env().expect("env keys");

        let clt = client::Client::new(pg_env).expect("client value");

        // Embedding request can contain text or an image. The image should be base64 encoded.
        let req = embedding::Request::new(
            models::Model::BridgetowerLargeItmMlmItc,
            Some("Tell me a joke.".to_string()),
            IMAGE.to_string(),
        );

        let result = clt.embedding(&req).await.expect("error from embeddings");

        println!("\n\nembedding response:\n{:?}\n\n", result);
    }
    ```
    </CodeBlock>

    <CodeBlock title="NodeJS">
    ```js
    import * as pg from 'predictionguard';

    const client = new pg.Client('https://api.predictionguard.com', process.env.PGKEY);

    async function Embedding() {
        const image = new pg.ImageNetwork('https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg');

        const input = [
            {
                text: 'Tell me a joke.',
                image: image,
            },
        ];

        var [result, err] = await client.Embedding(input);
        if (err != null) {
            console.log('ERROR:' + err.error);
            return;
        }

        for (const dt of result.data) {
            process.stdout.write(dt.embedding.toString());
        }
    }

    Embedding();
    ```
    </CodeBlock>

    <CodeBlock title="cURL">
    ```bash
    curl -O 'https://farm4.staticflickr.com/3300/3497460990_11dfb95dd1_z.jpg'
    
    base64_img="$(base64 -i 3497460990_11dfb95dd1_z.jpg)"
    
    cat <<EOF > input.json
    {
        "model": "bridgetower-large-itm-mlm-itc",
		"input": [
        	{
			"text": "Tell me a joke.",
            "image": "$base64_img"
          	}
    	]
    }
    EOF

    curl -i -X POST https://api.predictionguard.com/embeddings \
    -H "x-api-key: ${PGKEY}" \
    -H "Content-Type: application/json" \
    -d @input.json
    ```
    </CodeBlock>
</CodeBlocks>

The output will look something like this.

```json
{
   "id":"emb-oM1AChyqjQKqT6XKiUqY0bnqIUikK",
   "object":"embedding_batch",
   "created":1717780716,
   "model":"bridgetower-large-itm-mlm-itc",
   "data":[
      {
         "status":"error: could not call model, contact support",
         "index":0,
         "object":"embedding",
         "embedding":[
            
         ]
      }
   ]
}
```

This approach presents a straightforward way for readers to choose and apply the
code example that best suits their needs for generating text completions using
either Python, Go, Rust, JS, or cURL.
