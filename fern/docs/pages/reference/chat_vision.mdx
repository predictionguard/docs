---
title: Chat Vision
---

You can get vision text completions from any of the vision enabled
[models](/options/enumerations) using the `/chat/completions` REST API endpoint
or any of the official SDKs (Python, Go, Rust, JS, or cURL).

## Generate a Vision Text Completion

To generate a vision text completion, you can use the following code examples.
Depending on your preference or requirements, select the appropriate method for
your application. Streaming is not currently supported when generating a vision
text completion. For image inputs, this endpoint supports image file, url, and
base 64 encoded inputs in the python client, while the Go API only supports
images that are base64 encoded represented by a data uri.

<CodeBlocks>
    <CodeBlock title="Python">
    ```python
    import os
    import json

    from predictionguard import PredictionGuard

    # Set your Prediction Guard token as an environmental variable.
    os.environ["PREDICTIONGUARD_API_KEY"] = "<api key>"
    
    client = PredictionGuard()

    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "What's in this image?"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": "https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png",
                    }
                }
            ]
        },
    ]

    result = client.chat.completions.create(
        model="llava-1.5-7b-hf",
        messages=messages
    )

    print(json.dumps(
        result,
        sort_keys=True,
        indent=4,
        separators=(',', ': ')
    ))
    ```
    </CodeBlock>

    <CodeBlock title="Go">
    ```go
    package main

    import (
        "context"
        "fmt"
        "log"
        "os"
        "time"

        "github.com/predictionguard/go-client"
    )

    func main() {
        if err := run(); err != nil {
            log.Fatalln(err)
        }
    }

    func run() error {
        host := "https://staging.predictionguard.com"
        apiKey := os.Getenv("PREDICTIONGUARD_API_KEY")

        logger := func(ctx context.Context, msg string, v ...any) {
            s := fmt.Sprintf("msg: %s", msg)
            for i := 0; i < len(v); i = i + 2 {
                s = s + fmt.Sprintf(", %s: %v", v[i], v[i+1])
            }
            log.Println(s)
        }

        cln := client.New(logger, host, apiKey)

        ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()

        image, err := client.NewImageNetwork("https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png")
        if err != nil {
            return fmt.Errorf("ERROR: %w", err)
        }

        input := client.ChatVisionInput{
            Role:        client.Roles.User,
            Question:    "What's in this image?",
            Image:       image,
            MaxTokens:   1000,
            Temperature: 0.1,
            TopP:        0.1,
            TopK:        50.0,
        }

        resp, err := cln.ChatVision(ctx, input)
        if err != nil {
            return fmt.Errorf("ERROR: %w", err)
        }

        for i, choice := range resp.Choices {
            fmt.Printf("choice %d: %s\n", i, choice.Message.Content)
        }

        return nil
    }
    ```
    </CodeBlock>

    <CodeBlock title="Rust">
    ```rust
    extern crate prediction_guard as pg_client;

    use pg_client::chat::MessageVision;
    use pg_client::{chat, client, models};

    #[tokio::main]
    async fn main() {
        let pg_env = client::PgEnvironment::from_env().expect("env keys");

        let clt = client::Client::new(pg_env).expect("client value");

        let req = chat::Request::<MessageVision>::new(models::Model::Llava157bhf)
            .temperature(0.85)
            .max_tokens(1000)
            .add_message(
                chat::Roles::User,
                "What's in this image?".to_string(),
                IMAGE.to_string(),
            );

        let result = clt
            .generate_chat_vision(&req)
            .await
            .expect("error from generate chat completion");

        println!("\nchat completion response:\n\n {:?}", result);
    }
    ```
    </CodeBlock>

    <CodeBlock title="NodeJS">
    ```js
    import * as pg from 'predictionguard';

    const client = new pg.Client('https://api.predictionguard.com', process.env.PREDICTIONGUARD_API_KEY);

    async function ChatVision() {
        const image = new pg.ImageNetwork('https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png');

        const input = {
            role: pg.Roles.User,
            question: 'What's in this image?',
            image: image,
            maxTokens: 1000,
            temperature: 0.1,
            topP: 0.1,
            topK: 50.0,
        };

        var [result, err] = await client.ChatVision(input);
        if (err != null) {
            console.log('ERROR:' + err.error);
            return;
        }

        console.log('RESULT:' + result.createdDate() + ': ' + result.model + ': ' + result.choices[0].message.content);
    }

    ChatVision();
    ```
    </CodeBlock>

    <CodeBlock title="cURL">
    ```bash
    curl -O 'https://pbs.twimg.com/media/GKLN4qPXEAArqoK.png'
        
    base64_img="$(base64 -i 2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg)"

    cat <<EOF > input.json
    {
        "model": "llava-1.5-7b-hf",
        "messages": [
            {
            "role": "user",
            "content": [
                {
                "type": "text",
                "text": "What is in this image?"
                },
                {
                "type": "image_url",
                "image_url": {
                    "url": "data:image/jpeg;base64,$base64_img"
                }
                }
            ]
            }
        ],
        "max_tokens": 300
    }
    EOF

    curl -i -X POST https://api.predictionguard.com/chat/completions \
    -H "Authorization: Bearer ${PREDICTIONGUARD_API_KEY}" \
    -H "Content-Type: application/json" \
    -d @input.json
    ```
    </CodeBlock>
</CodeBlocks>

The output will look something like:

```json
{
   "id":"chat-zstjj2MKpRdKfBmCMILK9wgx7I09N",
   "object":"chat_completion",
   "created":1723228682,
   "model":"llava-1.5-7b-hf",
   "choices":[
      {
         "index":0,
         "message":{
            "role":"assistant",
            "content":"In the image, there is a person standing on the back of a vehicle in a city. The vehicle is situated next to a taxi on the street. Another car can be seen approaching, and there is also a traffic light visible in the scene. The person standing on the vehicle could be a man drying his clothes, creating a unique and eye-catching sight. Additionally, a handbag is present near the person riding on the vehicle, likely belonging to them.",
            "output":null
         },
         "status":"success"
      }
   ]
}
```

This approach presents a straightforward way for readers to choose and apply the
code example that best suits their needs for generating text completions using
either Python, Go, Rust, JS, or cURL.